# baseline.py

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
from xgboost import XGBClassifier

# ğŸ”¹ Step 1: è¯»å–è¡¨è¾¾çŸ©é˜µå’Œ phenotype æ•°æ®
expr = pd.read_csv("GSE78220_expr_clean.csv", index_col=0).T
pheno = pd.read_csv("GSE78220_pheno.csv", index_col=0)

# ğŸ”¹ Step 2: å¯¹é½æ ·æœ¬
X = expr.copy()
y = pheno.loc[X.index, "response_bin"]

# ğŸ” å¯é€‰ï¼šæ£€æŸ¥æ ‡ç­¾æ˜¯å¦ä¸º 0 å’Œ 1
print("æ ‡ç­¾åˆ†å¸ƒï¼š")
print(y.value_counts())

# ğŸ”¹ Step 3: åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)

# ğŸ”¹ Step 4: å»ºæ¨¡ï¼ˆXGBoostï¼‰
clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
clf.fit(X_train, y_train)

# ğŸ”¹ Step 5: é¢„æµ‹ä¸è¯„ä¼°
y_pred = clf.predict(X_test)
y_proba = clf.predict_proba(X_test)[:, 1]

print("\nğŸ¯ åˆ†ç±»ç»“æœï¼š")
print(classification_report(y_test, y_pred, digits=4))

auc = roc_auc_score(y_test, y_proba)
print(f"\nğŸ” AUC score: {auc:.4f}")
